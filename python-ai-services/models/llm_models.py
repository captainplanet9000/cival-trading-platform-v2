"""
Phase 10: LLM Integration Models
Data models for LLM integration and agent communication system
"""

from typing import Dict, List, Optional, Any, Union
from datetime import datetime, timezone
from dataclasses import dataclass, field
from enum import Enum
from decimal import Decimal
from pydantic import BaseModel, Field
import uuid

class LLMProvider(Enum):
    """Supported LLM providers"""
    OPENAI_GPT4 = "openai_gpt4"
    OPENAI_GPT35 = "openai_gpt35"
    ANTHROPIC_CLAUDE = "anthropic_claude"
    HUGGINGFACE_LOCAL = "huggingface_local"
    GOOGLE_PALM = "google_palm"
    COHERE = "cohere"

class LLMTaskType(Enum):
    """Types of LLM tasks"""
    MARKET_ANALYSIS = "market_analysis"
    TRADING_DECISION = "trading_decision"
    RISK_ASSESSMENT = "risk_assessment"
    PORTFOLIO_OPTIMIZATION = "portfolio_optimization"
    AGENT_COMMUNICATION = "agent_communication"
    GOAL_PLANNING = "goal_planning"
    STRATEGY_GENERATION = "strategy_generation"
    PERFORMANCE_ANALYSIS = "performance_analysis"
    NATURAL_LANGUAGE_QUERY = "natural_language_query"

class MessageType(Enum):
    """Types of conversation messages"""
    DISCUSSION = "discussion"
    PROPOSAL = "proposal"
    DECISION = "decision"
    QUESTION = "question"
    ANSWER = "answer"
    ALERT = "alert"
    SUMMARY = "summary"

class LLMRequest(BaseModel):
    """LLM request model"""
    request_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    task_type: LLMTaskType
    prompt: str
    context: Dict[str, Any] = Field(default_factory=dict)
    system_prompt: Optional[str] = None
    max_tokens: Optional[int] = None
    temperature: Optional[float] = None
    preferred_provider: Optional[LLMProvider] = None
    priority: int = Field(default=5, ge=1, le=10)
    timeout: Optional[int] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class LLMResponse(BaseModel):
    """LLM response model"""
    request_id: str
    provider: LLMProvider
    content: str
    tokens_used: int
    processing_time: float
    confidence_score: float = Field(ge=0.0, le=1.0)
    metadata: Dict[str, Any] = Field(default_factory=dict)
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class ConversationContext(BaseModel):
    """Conversation context model"""
    conversation_id: str
    participants: List[str]
    topic: str
    context: Dict[str, Any] = Field(default_factory=dict)
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    is_active: bool = True
    priority: int = Field(default=5, ge=1, le=10)

class AgentCommunication(BaseModel):
    """Agent communication model"""
    communication_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    conversation_id: str
    sender_id: str
    recipient_id: str  # Can be "all" for broadcast
    message_type: MessageType
    content: str
    context: Dict[str, Any] = Field(default_factory=dict)
    response_to: Optional[str] = None
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    is_processed: bool = False
    priority: int = Field(default=5, ge=1, le=10)

class TradingDecision(BaseModel):
    """Trading decision model generated by LLM"""
    decision_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    agent_id: str
    symbol: str
    action: str  # "buy", "sell", "hold"
    quantity: Decimal
    price_target: Optional[Decimal] = None
    stop_loss: Optional[Decimal] = None
    take_profit: Optional[Decimal] = None
    reasoning: str
    confidence: float = Field(ge=0.0, le=1.0)
    risk_assessment: Dict[str, Any] = Field(default_factory=dict)
    market_conditions: Dict[str, Any] = Field(default_factory=dict)
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    is_executed: bool = False
    execution_timestamp: Optional[datetime] = None

class MarketAnalysis(BaseModel):
    """Market analysis model generated by LLM"""
    analysis_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    analyst_id: str  # Agent or service ID
    symbols: List[str]
    timeframe: str
    market_sentiment: str
    key_insights: List[str]
    opportunities: List[Dict[str, Any]] = Field(default_factory=list)
    risks: List[Dict[str, Any]] = Field(default_factory=list)
    recommendations: List[Dict[str, Any]] = Field(default_factory=list)
    technical_indicators: Dict[str, Any] = Field(default_factory=dict)
    fundamental_factors: Dict[str, Any] = Field(default_factory=dict)
    confidence_score: float = Field(ge=0.0, le=1.0)
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    valid_until: Optional[datetime] = None

class LLMProviderConfig(BaseModel):
    """LLM provider configuration model"""
    provider: LLMProvider
    model_name: str
    api_key: Optional[str] = None
    endpoint: Optional[str] = None
    max_tokens: int = 2048
    temperature: float = 0.7
    timeout: int = 60
    cost_per_token: float = 0.0
    rate_limit_rpm: int = 100
    rate_limit_tpm: int = 10000
    is_enabled: bool = True
    priority: int = Field(default=5, ge=1, le=10)

class AgentPersonality(BaseModel):
    """Agent personality configuration model"""
    agent_id: str
    name: str
    role: str
    trading_style: str
    risk_tolerance: float = Field(ge=0.0, le=1.0)
    communication_style: str
    expertise_areas: List[str] = Field(default_factory=list)
    personality_traits: Dict[str, float] = Field(default_factory=dict)
    system_prompt: str
    preferred_provider: Optional[LLMProvider] = None
    response_patterns: Dict[str, str] = Field(default_factory=dict)
    is_active: bool = True
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class ConversationMessage(BaseModel):
    """Individual conversation message model"""
    message_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    conversation_id: str
    sender_id: str
    recipient_id: str
    content: str
    message_type: MessageType
    context: Dict[str, Any] = Field(default_factory=dict)
    response_to: Optional[str] = None
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    is_read: bool = False
    reactions: List[Dict[str, Any]] = Field(default_factory=list)
    attachments: List[Dict[str, Any]] = Field(default_factory=list)

class LLMUsageMetrics(BaseModel):
    """LLM usage metrics model"""
    provider: LLMProvider
    task_type: LLMTaskType
    total_requests: int = 0
    total_tokens: int = 0
    total_cost: Decimal = Decimal("0")
    avg_response_time: float = 0.0
    success_rate: float = 1.0
    error_count: int = 0
    last_request: Optional[datetime] = None
    date: str = Field(default_factory=lambda: datetime.now().strftime("%Y-%m-%d"))

class ConversationSummary(BaseModel):
    """Conversation summary model"""
    conversation_id: str
    topic: str
    participants: List[str]
    message_count: int
    key_decisions: List[str] = Field(default_factory=list)
    action_items: List[Dict[str, Any]] = Field(default_factory=list)
    consensus_reached: bool = False
    summary_text: str
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    generated_by: str = "llm_system"

class LLMPerformanceMetrics(BaseModel):
    """LLM performance metrics model"""
    provider: LLMProvider
    model_name: str
    accuracy_score: float = Field(ge=0.0, le=1.0)
    response_quality: float = Field(ge=0.0, le=1.0)
    consistency_score: float = Field(ge=0.0, le=1.0)
    cost_efficiency: float = Field(ge=0.0, le=1.0)
    speed_score: float = Field(ge=0.0, le=1.0)
    overall_score: float = Field(ge=0.0, le=1.0)
    evaluation_date: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    sample_size: int = 0
    evaluation_criteria: Dict[str, Any] = Field(default_factory=dict)

class NaturalLanguageQuery(BaseModel):
    """Natural language query model"""
    query_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_id: str
    query_text: str
    intent: Optional[str] = None
    entities: Dict[str, Any] = Field(default_factory=dict)
    context: Dict[str, Any] = Field(default_factory=dict)
    response: Optional[str] = None
    confidence: Optional[float] = None
    processing_time: Optional[float] = None
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    is_processed: bool = False

class StrategyGeneration(BaseModel):
    """Strategy generation model"""
    strategy_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    generated_by: str  # Agent or service ID
    strategy_name: str
    strategy_type: str
    description: str
    parameters: Dict[str, Any] = Field(default_factory=dict)
    entry_conditions: List[str] = Field(default_factory=list)
    exit_conditions: List[str] = Field(default_factory=list)
    risk_management: Dict[str, Any] = Field(default_factory=dict)
    expected_return: Optional[float] = None
    max_drawdown: Optional[float] = None
    win_rate: Optional[float] = None
    confidence_score: float = Field(ge=0.0, le=1.0)
    backtesting_results: Dict[str, Any] = Field(default_factory=dict)
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    is_validated: bool = False

class RiskAssessment(BaseModel):
    """Risk assessment model generated by LLM"""
    assessment_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    assessor_id: str  # Agent or service ID
    assessment_type: str  # "portfolio", "position", "strategy"
    target_id: str  # Portfolio, position, or strategy ID
    risk_level: str  # "low", "medium", "high", "extreme"
    risk_score: float = Field(ge=0.0, le=100.0)
    risk_factors: List[Dict[str, Any]] = Field(default_factory=list)
    mitigation_strategies: List[str] = Field(default_factory=list)
    recommendations: List[str] = Field(default_factory=list)
    stress_test_results: Dict[str, Any] = Field(default_factory=dict)
    confidence: float = Field(ge=0.0, le=1.0)
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    valid_until: Optional[datetime] = None

class GoalPlan(BaseModel):
    """Goal planning model generated by LLM"""
    plan_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    planner_id: str  # Agent or service ID
    goal_id: str
    goal_description: str
    milestones: List[Dict[str, Any]] = Field(default_factory=list)
    strategies: List[str] = Field(default_factory=list)
    resource_requirements: Dict[str, Any] = Field(default_factory=dict)
    timeline: Dict[str, Any] = Field(default_factory=dict)
    success_criteria: List[str] = Field(default_factory=list)
    risk_factors: List[str] = Field(default_factory=list)
    contingency_plans: List[Dict[str, Any]] = Field(default_factory=list)
    estimated_probability: float = Field(ge=0.0, le=1.0)
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    is_approved: bool = False

class LLMPromptTemplate(BaseModel):
    """LLM prompt template model"""
    template_id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    name: str
    description: str
    task_type: LLMTaskType
    template_text: str
    variables: List[str] = Field(default_factory=list)
    system_prompt: Optional[str] = None
    examples: List[Dict[str, str]] = Field(default_factory=list)
    optimal_provider: Optional[LLMProvider] = None
    parameters: Dict[str, Any] = Field(default_factory=dict)
    tags: List[str] = Field(default_factory=list)
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    is_active: bool = True
    usage_count: int = 0
    average_rating: float = 0.0

# Request/Response models for API endpoints
class CreateConversationRequest(BaseModel):
    """Request to create a new conversation"""
    participants: List[str]
    topic: str
    context: Dict[str, Any] = Field(default_factory=dict)
    priority: int = Field(default=5, ge=1, le=10)

class SendMessageRequest(BaseModel):
    """Request to send a message in a conversation"""
    conversation_id: str
    sender_id: str
    content: str
    message_type: MessageType = MessageType.DISCUSSION
    context: Dict[str, Any] = Field(default_factory=dict)
    recipient_id: str = "all"

class GenerateAnalysisRequest(BaseModel):
    """Request to generate market analysis"""
    symbols: List[str]
    timeframe: str = "1h"
    analysis_type: str = "comprehensive"
    agent_id: Optional[str] = None
    context: Dict[str, Any] = Field(default_factory=dict)

class GenerateStrategyRequest(BaseModel):
    """Request to generate trading strategy"""
    strategy_type: str
    market_conditions: Dict[str, Any]
    risk_tolerance: float = Field(ge=0.0, le=1.0)
    capital_amount: Decimal
    timeframe: str = "1d"
    context: Dict[str, Any] = Field(default_factory=dict)

class AssessRiskRequest(BaseModel):
    """Request to assess risk"""
    assessment_type: str
    target_id: str
    current_positions: List[Dict[str, Any]] = Field(default_factory=list)
    market_data: Dict[str, Any] = Field(default_factory=dict)
    context: Dict[str, Any] = Field(default_factory=dict)

class NaturalLanguageQueryRequest(BaseModel):
    """Request for natural language query processing"""
    query_text: str
    user_id: str
    context: Dict[str, Any] = Field(default_factory=dict)
    preferred_response_format: str = "text"

# Response models
class ConversationResponse(BaseModel):
    """Response for conversation operations"""
    conversation_id: str
    status: str
    message: str
    participants: List[str]
    message_count: int
    created_at: datetime

class MessageResponse(BaseModel):
    """Response for message operations"""
    message_id: str
    conversation_id: str
    status: str
    timestamp: datetime
    enhanced_content: str

class AnalysisResponse(BaseModel):
    """Response for analysis generation"""
    analysis_id: str
    status: str
    analysis: MarketAnalysis
    processing_time: float
    tokens_used: int

class StrategyResponse(BaseModel):
    """Response for strategy generation"""
    strategy_id: str
    status: str
    strategy: StrategyGeneration
    processing_time: float
    tokens_used: int

class RiskResponse(BaseModel):
    """Response for risk assessment"""
    assessment_id: str
    status: str
    assessment: RiskAssessment
    processing_time: float
    tokens_used: int

class QueryResponse(BaseModel):
    """Response for natural language query"""
    query_id: str
    status: str
    response_text: str
    intent: Optional[str]
    entities: Dict[str, Any]
    confidence: float
    processing_time: float